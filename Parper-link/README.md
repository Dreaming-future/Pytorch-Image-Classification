# ClassicNetwork 图像分类网络论文链接汇总

Classical network implemented by pytorch

**LeNet:**

- **LeNet:** LeNet-5, convolutional neural networks

  [http://yann.lecun.com/exdb/lenet/index.html](http://yann.lecun.com/exdb/lenet/index.html)

**AlexNet:**

- ImageNet Classification with Deep Convolutional Neural Networks, Alex Krizhevsky, 2012

  [http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

**VGG:**

- Very Deep Convolutional Networks for Large-Scale Image Recognition,Karen Simonyan,2014

  [https://arxiv.org/abs/1409.1556](https://arxiv.org/abs/1409.1556)

**ResNet:**

- Deep Residual Learning for Image Recognition, He-Kaiming, 2016

  [https://arxiv.org/abs/1512.03385](https://arxiv.org/abs/1512.03385)

**Batch Normalization**

- Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift,2015

  [https://arxiv.org/abs/1502.03167](https://arxiv.org/abs/1502.03167)

**ZFNet**

- Visualizing and Understanding Convolutional Networks,2013

  [https://arxiv.org/abs/1311.2901](https://arxiv.org/abs/1311.2901)

**Inception系列**

- **InceptionV1:** Going deeper with convolutions , Christian Szegedy , 2014

  [https://arxiv.org/abs/1409.4842](https://arxiv.org/abs/1409.4842)

- **InceptionV2 and InceptionV3:** Rethinking the Inception Architecture for Computer Vision , Christian Szegedy ,2015

  [https://arxiv.org/abs/1512.00567](https://arxiv.org/abs/1512.00567)

- **InceptionV4 and Inception-ResNet:** Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning , Christian Szegedy ,2016

  [https://arxiv.org/abs/1602.07261](https://arxiv.org/abs/1602.07261)

**DenseNet:**

- Densely Connected Convolutional Networks, 2017

  [https://arxiv.org/abs/1608.06993](https://arxiv.org/abs/1608.06993)

**ResNeXt:**

- Aggregated Residual Transformations for Deep Neural Networks,2017

  [https://arxiv.org/abs/1611.05431](https://arxiv.org/abs/1611.05431)

**NASNet:**

- Learning Transferable Architectures for Scalable Image Recognition

  [https://arxiv.org/abs/1707.07012](https://arxiv.org/abs/1707.07012)

**SENet**

- Squeeze-and-Excitation Networks

  [https://arxiv.org/abs/1709.01507](https://arxiv.org/abs/1709.01507)

**MobileNet:**

- **MobileNet(v1)** : MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications

  [https://arxiv.org/abs/1704.04861](https://arxiv.org/abs/1704.04861)

- **MobileNet(v2)** : MobileNetV2: Inverted Residuals and Linear Bottlenecks

  [https://arxiv.org/abs/1801.04381](https://arxiv.org/abs/1801.04381)

- **MobileNet(v3)** : Searching for MobileNetV3

  [https://arxiv.org/abs/1905.02244](https://arxiv.org/abs/1905.02244)



**ShuffleNet:**

- **ShuffleNet(v1)** :ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices

  [https://arxiv.org/abs/1707.01083](https://arxiv.org/abs/1707.01083)

- **ShuffleNet(v2)** :ShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design

  [https://arxiv.org/abs/1807.11164](https://arxiv.org/abs/1807.11164)

**EfficientNet:**

- EfficientNet(v1) :EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks

  [https://arxiv.org/abs/1905.11946](https://arxiv.org/abs/1905.11946)

- EfficientNet(v2) :EfficientNetV2: Smaller Models and Faster Training

  [https://arxiv.org/abs/2104.00298](https://arxiv.org/abs/2104.00298)